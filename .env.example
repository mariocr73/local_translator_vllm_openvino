# Modelo a usar (3B para balance Ã³ptimo de calidad y velocidad)
# Recommended: Qwen/Qwen2.5-3B-Instruct
# Alternative: Qwen/Qwen2.5-7B-Instruct (better quality, slower)
MODEL_ID=Qwen/Qwen2.5-3B-Instruct

# Maximum model context length
MAX_MODEL_LEN=8192

# vLLM server port
VLLM_PORT=8000

# Optional: HuggingFace Hub token (only needed for private models)
# Leave empty for public models
HUGGINGFACE_HUB_TOKEN=
